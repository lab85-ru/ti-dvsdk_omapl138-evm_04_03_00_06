/* 
 * Copyright (c) 2010, Texas Instruments Incorporated
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *
 * *  Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 *
 * *  Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * *  Neither the name of Texas Instruments Incorporated nor the names of
 *    its contributors may be used to endorse or promote products derived
 *    from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
 * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
 * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
 * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
 * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
 * EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 * 
 */
/*
 *  ======== Memory_cmem.c ========
 */
#include <xdc/std.h>

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <assert.h>

#include <ti/sdo/ce/osal/Global.h>
#include <ti/sdo/utils/trace/gt.h>
#include <ti/sdo/winceutils/cmem/cmem.h>
#include <ti/sdo/ce/osal/Lock.h>

#include <ti/sdo/ce/osal/Memory.h>

/* default memory segment */
#define DEFAULTSEGMENTID    0

/* recordkeeping for CMEM allocations and address translations so that
 * quick lookups and reverse translations are possible.
 * This is a simple, unordered linked-list. The assumption
 * is that the number of contiguous, physical buffers we know over time
 * reaches a maximum, which furthermore is fairly small.
 *
 * TODO:H verify there's no case where this list grows indefinitely.
 *        If the application frees CMEM-allocated buffer, we will know so
 *        the list will shrink. If the app maps and unmaps (outside of CE)
 *        buffers, "stale" physical buffers for now non-existent virtual
 *        addresses will get their virtual addresses updated if the same
 *        region is ever mapped and sent to translation.
 */
typedef struct ContigBuf {
    UInt32 virtualAddress;
    UInt32 sizeInBytes;
    UInt32 physicalAddress;
    struct ContigBuf *next;
} ContigBuf;

/* REMINDER: if you add an initialized static var, reinitialize it at cleanup */
static Bool curInit = FALSE;

static ContigBuf  *contigBufList = NULL;

static Bool cmemInitialized = FALSE;
static Lock_Handle moduleLock = NULL;
static Int numCmemBlocks = 0;

static GT_Mask curTrace;

/* generated by Global.xdt: max size of the memory contig buffer cached list */
extern Int Memory_maxCbListSize;

/*
 * Memory_DEFAULTPARAMS should be set such that legacy Memory_alloc behavior
 * is achieved (where "legacy" means before params were added).
 */
Memory_AllocParams Memory_DEFAULTPARAMS = {
    Memory_MALLOC,
    Memory_NONCACHED,
    Memory_DEFAULTALIGNMENT,
    DEFAULTSEGMENTID
};

/* defined by Global.xdt: if the system configurator set this option to true,
 * it means he knows ALL the calls to this function (from VISA functions, when
 * this library is used with Codec Engine) will be getting physical addresses
 * and not virtual ones; in that case, we play along and in
 * Memory_getBufferPhysicalAddress() we return the given virtual address
 * as physical, unchanged.
 * (For Memory_getBufferVirtualAddress(), we always return the given physical
 * address as virtual if this flag is on.)
 */
extern Bool Memory_skipVirtualAddressTranslation;

static Ptr myMalloc(UInt size);

static Void cleanup(Void);
static Bool stat(Memory_Stat *statbuf);
static Ptr contigAlloc(UInt size, UInt align, Bool cacheable, Bool heap,
        Int blockId);
static Bool contigFree(Ptr addr, UInt size, Int type);

/*
 *  ======== addContigBuf ========
 */
static ContigBuf *addContigBuf(UInt32 virtualAddress, UInt32 sizeInBytes,
        UInt32 physicalAddress)
{
    ContigBuf *cb;
    Int        cbCount = 0;

    GT_3trace(curTrace, GT_1CLASS, "Memory__addContigBuf> "
            "Enter(virtAddr=0x%x, size=%d, physAddr=0x%x)\n",
            virtualAddress, sizeInBytes, physicalAddress);

    for (cb = contigBufList; cb != NULL; cb = cb->next) {

        /* check if the submitted contigbuf intersects current contigbuf;
         * (notation: { } is "current", [ ] is "submitted"
         * 1. if submitted cb is a subset of current cb, return current cb;
         * 2. if current cb is a subset of submitted cb, set current cb
         *    to submitted cb, return current cb
         * 3. if they intersect but neither is a subset of the other,
         *    set current cb to union of current and submitted, return cur
         */
        UInt32 startCurrent   = cb->physicalAddress;
        UInt32 endCurrent     = startCurrent + cb->sizeInBytes;
        UInt32 startSubmitted = physicalAddress;
        UInt32 endSubmitted   = physicalAddress + sizeInBytes;

        if ((startCurrent <= startSubmitted) && (endCurrent >= endSubmitted)) {
            /*
             *  case 1: The submitted buffer is contained in a listed buffer
             *  {[      ]}
             */
            GT_4trace(curTrace, GT_1CLASS, "Memory__addContigBuf> "
                    "case 1 (Sc=0x%x, Ec=0x%x, Ss=0x%x, Es=0x%x\n",
                    startCurrent, endCurrent, startSubmitted, endSubmitted);
            /*
             *  COMMENT (jeh): This step does not seem necessary. If anyone
             *  knows why this should be done, please add a comment to the
             *  code.
             */
            cb->virtualAddress =
                virtualAddress - (startSubmitted - startCurrent);
            break;
        }

        if ((startSubmitted <= startCurrent) && (endSubmitted >= endCurrent)) {
            /*
             *  case 2:  The submitted buffer contains one of the buffers
             *  in the list [{      }]
             */
            GT_4trace(curTrace, GT_1CLASS, "Memory__addContigBuf> "
                    "case 2 (Sc=0x%x, Ec=0x%x, Ss=0x%x, Es=0x%x\n",
                    startCurrent, endCurrent, startSubmitted, endSubmitted);
            cb->physicalAddress = physicalAddress;
            cb->sizeInBytes     = sizeInBytes;
            cb->virtualAddress  = virtualAddress;
            break;
        }

        if ((startCurrent <= startSubmitted) && (startSubmitted < endCurrent)){
            /*
             *  case 3a: {[     }  ]
             *  [dm] per fix for a bug noted in ce-b21: cb's should not be
             *  merged if they merely *touch* -- only if they truly overlap;
             *  adjacency in the virtual space doesn't guarantee adjacency
             *  in physical space, and vice versa; so we merge only
             *  if endCurrent > startSubmitted, not if >=.
             *
             *  NOTE: We know that endCurrent < endSubmitted, otherwise we
             *  would have gone through case 1.
             */
            GT_4trace(curTrace, GT_1CLASS, "Memory__addContigBuf> "
                    "case 3a (Sc=0x%x, Ec=0x%x, Ss=0x%x, Es=0x%x\n",
                    startCurrent, endCurrent, startSubmitted, endSubmitted);
            cb->sizeInBytes = endSubmitted - startCurrent;

            /*
             *  COMMENT (jeh): Again, why is this step necessary?
             */
            cb->virtualAddress =
                virtualAddress - (startSubmitted - startCurrent);
            break;
        }

        if ((startSubmitted <= startCurrent) && (startCurrent < endSubmitted)){
            /*
             *  case 3b: [{     ]  }
             *  ... and here we merge only if endSubmitted > startCurrent.
             *
             *  NOTE: We know that endCurrent > endSubmitted, otherwise we
             *  would have been covered by case 2.
             */
            GT_4trace(curTrace, GT_1CLASS, "Memory__addContigBuf> "
                    "case 3b (Sc=0x%x, Ec=0x%x, Ss=0x%x, Es=0x%x\n",
                    startCurrent, endCurrent, startSubmitted, endSubmitted);
            cb->physicalAddress = physicalAddress;
            cb->virtualAddress  = virtualAddress;
            cb->sizeInBytes     = endCurrent - startSubmitted;
            break;
        }

        /* submitted and current cb are completely disjoint */

        /*
         *  Delete old elements; the caller has the lock acquired.
         *  This is ok, since the ContigBuf elements are used only as a
         *  convinience for quick lookups.
         */
        if ((++cbCount > Memory_maxCbListSize) && (cb->next != NULL)) {
            ContigBuf *cbNext = cb->next;
            cb->next = cbNext->next;
            Memory_free(cbNext, sizeof(ContigBuf), NULL);
        }
    }

    if (cb == NULL) {
        /* either because it's the first or no match was found */
        GT_0trace(curTrace, GT_1CLASS, "Memory__addContigBuf> "
                "creating new contigBuf object\n");
        cb = Memory_alloc(sizeof(ContigBuf), NULL);
        if (cb == NULL) {
            goto addContigBuf_return;
        }
        cb->virtualAddress  = virtualAddress;
        cb->sizeInBytes     = sizeInBytes;
        cb->physicalAddress = physicalAddress;

        cb->next = contigBufList;
        contigBufList = cb;
    }

addContigBuf_return:

    if (cb) {
        GT_3trace(curTrace, GT_1CLASS, "Memory__addContigBuf> "
                "returning: cb->phys=0x%x, cb->size=%d, cb->virt=0x%x\n",
                cb->physicalAddress, cb->sizeInBytes, cb->virtualAddress);
    }
    else {
        GT_0trace(curTrace, GT_7CLASS, "Memory__addContigBuf> out of Memory\n");
    }

    return (cb);
}


/*
 *  ======== removeContigBuf ========
 */
static Int removeContigBuf(UInt32 virtualAddress, UInt32 sizeInBytes)
{
    int rv = 0;
    ContigBuf *cb, *prevCb;

    GT_2trace(curTrace, GT_1CLASS, "Memory__removeContigBuf> "
            "Enter(virtAddr=0x%x, size=%d)\n", virtualAddress, sizeInBytes);

    cb = contigBufList;
    prevCb = NULL;

    while (cb != NULL) {
        if ((cb->virtualAddress == virtualAddress) &&
                (cb->sizeInBytes == sizeInBytes)) {
            GT_3trace(curTrace, GT_1CLASS, "Memory__removeContigBuf> "
                    "removing cb->phys=0x%x, cb->size=0x%x, cb->virt=0x%x\n",
                    cb->physicalAddress, cb->sizeInBytes, cb->virtualAddress);
            if (prevCb == NULL) {
                contigBufList = cb->next;
            } else {
                prevCb->next =  cb->next;
            }
            Memory_free(cb, sizeof(ContigBuf), NULL);
            break;
        }
        prevCb = cb;
        cb = cb->next;
    }

    if (cb == NULL) {
        GT_0trace(curTrace, GT_1CLASS, "Memory__removeContigBuf> "
                "ERROR: Failed to find matching cb\n");
        rv = -1;
    }

    return (rv);
}


/*
 *  ======== getPhysicalAddress ========
 */
static UInt32 getPhysicalAddress(UInt32 virtualAddress, UInt32 sizeInBytes)
{
    UInt32     physicalAddress = 0;
    ContigBuf *cb;

    GT_2trace(curTrace, GT_1CLASS, "Memory__getPhysicalAddress> "
            "Enter(virtAddr=0x%x, size=%d)\n", virtualAddress, sizeInBytes);

    for (cb = contigBufList; cb != NULL; cb = cb->next) {

        UInt32 startCurrent   = cb->virtualAddress;
        UInt32 endCurrent     = startCurrent + cb->sizeInBytes;
        UInt32 startSubmitted = virtualAddress;
        UInt32 endSubmitted   = virtualAddress + sizeInBytes;

        /*
         *  check if the submitted contigbuf is a subset of (or matches) the
         *  current contigbuf.
         */
        if ((startCurrent <= startSubmitted) && (endSubmitted <= endCurrent)) {
            /* case 1:  {[      ]} */
            GT_5trace(curTrace, GT_1CLASS, "Memory__getPhysicalAddress> "
                    "found in cb(Sc=0x%x, Ec=0x%x, Ss=0x%x, Es=0x%x, "
                    "PSc=0x%x)\n", startCurrent, endCurrent,
                    startSubmitted, endSubmitted, cb->physicalAddress);
            physicalAddress = cb->physicalAddress + (startSubmitted -
                    startCurrent);
            break;
        }
    }

    GT_1trace(curTrace, GT_1CLASS, "Memory__getPhysicalAddress> "
            "returning physAddr=0x%x\n", physicalAddress);

    return (physicalAddress);
}


/*
 *  ======== getVirtualAddress ========
 */
static UInt32 getVirtualAddress(UInt32 physicalAddress, UInt32 sizeInBytes)
{
    UInt32     virtualAddress = 0;
    ContigBuf *cb;

    GT_2trace(curTrace, GT_1CLASS, "Memory__getVirtualAddress> "
            "Enter(physAddr=0x%x, size=%d)\n", physicalAddress, sizeInBytes);

    for (cb = contigBufList; cb != NULL; cb = cb->next) {

        UInt32 startCurrent   = cb->physicalAddress;
        UInt32 endCurrent     = startCurrent + cb->sizeInBytes;
        UInt32 startSubmitted = physicalAddress;
        UInt32 endSubmitted   = physicalAddress + sizeInBytes;

        /* check if the submitted contigbuf is a subset of the current
         * contigbuf.
         */
        if (startCurrent <= startSubmitted &&
                endCurrent >= endSubmitted) {    /* case 1:  { [      ] } */
            GT_4trace(curTrace, GT_1CLASS, "Memory__getVirtualAddress> "
                    "found in cb(Sc=0x%x, Ec=0x%x, Ss=0x%x, Es=0x%x)\n",
                    startCurrent, endCurrent, startSubmitted, endSubmitted);
            virtualAddress = cb->virtualAddress + startSubmitted - startCurrent;
            break;                             /* result:    ^          */
        }
    }

    if (virtualAddress == 0) {
        GT_2trace(curTrace, GT_7CLASS, "Memory_getVirtualAddress> "
            "Error: buffer (physAddr=0x%x, size=0x%x) not found in translation"
            "cache\n\nEnsure that you have registered this buffer with "
            "Memory_registerContigBuf()\n", physicalAddress, sizeInBytes);
    }

    GT_1trace(curTrace, GT_1CLASS, "Memory__getVirtualAddress> "
            "returning virtAddr=0x%x\n", virtualAddress);

    return (virtualAddress);
}

/*
 *  ======== Memory_alloc ========
 */
Ptr Memory_alloc(UInt size, Memory_AllocParams *params)
{
    Void *ptr = NULL;
    Bool cached;
    Bool heap;
    Int  blockId;

    GT_1trace(curTrace, GT_ENTER, "Memory_alloc> Enter(0x%lx)\n", size);

    if (params == NULL) {
        params = &Memory_DEFAULTPARAMS;
    }

    switch (params->type) {
        case Memory_MALLOC:
        case Memory_SEG:
            ptr = myMalloc(size);

            break;

        case Memory_CONTIGPOOL:
        case Memory_CONTIGHEAP:
            blockId = params->seg;
            if (blockId >= numCmemBlocks) {
                GT_2trace(curTrace, GT_7CLASS,
                        "Memory_alloc> params->seg [%d] is "
                        "greater than the largest CMEM block number [%]. "
                        "Returning NULL\n", blockId, numCmemBlocks);
                return (NULL);
            }

            cached = (params->flags & Memory_CACHEDMASK) == Memory_CACHED ?
                TRUE : FALSE;
            heap = params->type == Memory_CONTIGHEAP ? TRUE : FALSE;
            ptr = contigAlloc(size, params->align, cached, heap, blockId);

            break;

        default:
            break;
    }

    GT_1trace(curTrace, GT_ENTER, "Memory_alloc> return (0x%x)\n", ptr);

    return (ptr);
}

static Ptr myMalloc(UInt size)
{
    Ptr addr = malloc(size);

    if (addr != NULL) {
        memset(addr, '\0', size);
    }
    else {
        GT_0trace(curTrace, GT_7CLASS, "Memory_alloc> "
                "ERROR: malloc() failed -- out of memory??\n");
    }

    return (addr);
}

/*
 *  ======== Memory_free ========
 */
Bool Memory_free(Ptr addr, UInt size, Memory_AllocParams *params)
{
    Bool rv = TRUE;

    GT_2trace(curTrace, GT_ENTER, "Memory_free> Enter(0x%lx, 0x%lx)\n",
            addr, size);

    if (params == NULL) {
        params = &Memory_DEFAULTPARAMS;
    }

    switch (params->type) {
        case Memory_MALLOC:
        case Memory_SEG:
            free(addr);

            break;

        case Memory_CONTIGPOOL:
            rv = contigFree(addr, size, CMEM_POOL);

            break;

        case Memory_CONTIGHEAP:
            rv = contigFree(addr, size, CMEM_HEAP);

            break;

        default:
            break;
    }

    GT_1trace(curTrace, GT_ENTER, "Memory_free> return (0x%x)\n", rv);

    return (rv);
}

/*
 *  ======== stat ========
 */
static Bool stat(Memory_Stat *statbuf)
{
    /* [dm]TODO:L implement some of this some day, if someone asks */
    statbuf->name   = NULL;
    statbuf->size   = 0;
    statbuf->used   = 0;
    statbuf->length = 0;
    return (TRUE);
}

/*
 *  ======== Memory_getHeapId ========
 */
Int Memory_getHeapId(String name)
{
    /* unsupported, return -1 */
    return (-1);
}

/*
 *  ======== Memory_getNumHeaps ========
 */
Int Memory_getNumHeaps()
{
    return (1);
}

/*
 *  ======== Memory_redefine ========
 */
Bool Memory_redefine(Int segId, Uint32 base, Uint32 size)
{
    /* unsupported, return FALSE */
    return (FALSE);
}

/*
 *  ======== Memory_restoreHeap ========
 */
Bool Memory_restoreHeap(Int segId)
{
    /* unsupported, return FALSE */
    return (FALSE);
}

/*
 *  ======== Memory_segAlloc ========
 */
Ptr Memory_segAlloc(Int segid, UInt size, UInt align)
{
    /* assert(segid == DEFAULTSEGMENTID); */
    return (myMalloc(size));
}
/*
 *  ======== Memory_segFree ========
 */
Bool Memory_segFree(Int segid, Ptr addr, UInt size)
{
    /* assert(segid == DEFAULTSEGMENTID); */
    return (Memory_free(addr, size, NULL));
}
/*
 *  ======== Memory_segStat ========
 */
Bool Memory_segStat(Int segid, Memory_Stat *statbuf)
{
    GT_2trace(curTrace, GT_ENTER, "Memory_segStat> Enter(0x%x, 0x%x)\n",
            segid, statbuf);

    if (segid == 0) {
        /* assert(segid == DEFAULTSEGMENTID); */
        stat(statbuf);
        return (TRUE);
    }
    else {
        return (FALSE);
    }
}


/*
 *  ======== Memory_init ========
 */
Bool Memory_init(Void)
{
    Int     status;

    if (curInit != TRUE) {
        curInit = TRUE;
        GT_create(&curTrace, Memory_GTNAME);
        moduleLock = Lock_create(NULL);
        if (moduleLock == NULL) {
            GT_0trace(curTrace, GT_7CLASS, "Memory_init> "
                    "ERROR: could not create pthread mutex.\n");
            assert(FALSE);
        }

        if (CMEM_init() == -1) {
            GT_0trace(curTrace, GT_7CLASS, "Memory_init> "
                    "ERROR: Failed to initialize CMEM\n");
        }
        else {
            cmemInitialized = TRUE;
            status = CMEM_getNumBlocks(&numCmemBlocks);
            if (status != 0) {
                GT_0trace(curTrace, GT_7CLASS, "Processor_create_d> "
                        "CMEM_getNumBlocks() failed!");
                numCmemBlocks = 0;
            }
        }

        Global_atexit((Fxn)cleanup);
    }

    return (cmemInitialized);
}


/*
 *  ======== Memory_exit ========
 */
Void Memory_exit(Void)
{
}


/*
 *  ======== contigAlloc ========
 */
static Ptr contigAlloc(UInt size, UInt align, Bool cacheable, Bool heap,
        Int blockId)
{
    Ptr    addr = NULL;
    UInt32 physAddr;
    CMEM_AllocParams cmemParams;

    /* lock acquire should be after the trace, but it's unlikely to fail
     * and we get a more consistent/less confusing output this way.
     */
    Lock_acquire(moduleLock);

    GT_5trace(curTrace, GT_ENTER, "Memory_contigAlloc> "
            "Enter(size=%d, align=%d, cached=%s, heap=%s, block=%d)\n",
            size, align, cacheable ? "TRUE" : "FALSE", heap ? "TRUE" : "FALSE",
            blockId);

    if (!cmemInitialized) {
        GT_1trace(curTrace, GT_7CLASS, "Memory_contigAlloc> "
                "ERROR: request for size=%d failed -- CMEM has not been "
                "initialized.\n", size);
        goto contigAlloc_return;
    }

    if (!heap && (align != Memory_DEFAULTALIGNMENT)) {
        align = Memory_DEFAULTALIGNMENT;
        GT_1trace(curTrace, GT_6CLASS, "Memory_contigAlloc> "
                "Warning: non-default alignment not supported "
                "for pool-based allocations, using default %#x.\n", align);
    }

    cmemParams.type = heap ? CMEM_HEAP : CMEM_POOL;
    cmemParams.flags = cacheable ? CMEM_CACHED : CMEM_NONCACHED;
    cmemParams.alignment = align;
    addr = CMEM_alloc2(blockId, size, &cmemParams);

    GT_2trace(curTrace, GT_4CLASS, "Memory_contigAlloc> "
            "CMEM_alloc(%d) = 0x%x.\n", size, addr);

    if (addr != NULL) {

        /* since the allocation succeeded, get physical address now and add the
         * description for this buffer in our list of contiguous buffers.
         */
        physAddr = CMEM_getPhys(addr);
        if (physAddr != 0) {
            GT_2trace(curTrace, GT_4CLASS, "Memory_contigAlloc> "
                    "CMEM_getPhys(0x%x) = 0x%x.\n", addr, physAddr);
            addContigBuf((Uint32)addr, size, physAddr);
        } else {
            GT_1trace(curTrace, GT_7CLASS, "Memory_contigAlloc> "
                    "ERROR: CMEM_getPhys(0x%x) (virt-to-phys) failed; "
                    "releasing the block.\n", addr);
            CMEM_free(addr, &cmemParams);
            addr = NULL;
        }
    } else {
        GT_0trace(curTrace, GT_7CLASS, "Memory_contigAlloc> "
                "ERROR: CMEM alloc failed\n");
    }

contigAlloc_return:

    GT_1trace(curTrace, GT_ENTER, "Memory_contigAlloc> return (0x%x)\n", addr);

    Lock_release(moduleLock);

    return addr;
}


/*
 *  ======== Memory_contigAlloc ========
 */
Ptr Memory_contigAlloc(UInt size, UInt align)
{
    return contigAlloc(size, align, FALSE, FALSE, 0);
}


/*
 *  ======== contigFree ========
 */
static Bool contigFree(Ptr addr, UInt size, Int type)
{
    Bool retVal = FALSE;
    CMEM_AllocParams cmemParams;

    GT_2trace(curTrace, GT_ENTER, "Memory_contigFree> "
            "Enter(addr=%d, size=%d)\n", addr, size);

    if (!cmemInitialized) {
        return (FALSE);
    }

    Lock_acquire( moduleLock );

    /* CMEM_free uses just the 'type' param */
    cmemParams.type = type;
    if (CMEM_free(addr, &cmemParams) == 0) {
        if (removeContigBuf((UInt32)addr, size) < 0) {
            GT_2trace(curTrace, GT_6CLASS, "Memory_contigFree> Warning: "
                    "removeContigBuf(0x%x, 0x%x) failed. Either buffer was "
                    "evicted from contig buf list (ok), or invalid size was "
                    "passed (bad). Verify params passed to Memory_free()\n",
                    addr, size);
        }
        retVal = TRUE;
    }
    else {
        GT_1trace(curTrace, GT_6CLASS, "Memory_contigFree> "
                "Warning: CMEM_free(0x%x) failed\n", addr);
        retVal = FALSE;
    }

    Lock_release(moduleLock);

    GT_1trace(curTrace, GT_ENTER, "Memory_contigFree> return (0x%x)\n",
            retVal);

    return (retVal);

}


/*
 *  ======== Memory_contigFree ========
 */
Bool Memory_contigFree(Ptr addr, UInt size)
{
    return (contigFree(addr, size, CMEM_POOL));
}


/*
 *  ======== Memory_contigStat ========
 */
Bool Memory_contigStat(Memory_Stat *statbuf)
{
    return (stat(statbuf));
}


/*
 *  ======== Memory_getBufferPhysicalAddress ========
 *  Converts user virtual address to physical address,
 *  but also verifies that the buffer is really contiguous
 *  and does some bookkeeping so that reverse mapping is possible.
 *  Returns 0 on failure, physical address on success.
 *  *isContiguous is set to TRUE or FALSE if isContiguous!=NULL.
 */
UInt32 Memory_getBufferPhysicalAddress(
           Ptr virtualAddress, Int sizeInBytes,    /* input */
           Bool *isContiguous                      /* output */
      )
{
    UInt32 physicalAddress = 0;
    UInt32 physicalAddressOfLastByte;

    Lock_acquire(moduleLock);

    GT_2trace(curTrace, GT_ENTER, "Memory_getBufferPhysicalAddress> "
            "Enter(virtAddr=0x%x, size=%d)\n", virtualAddress, sizeInBytes);

    if (Memory_skipVirtualAddressTranslation == TRUE) {
        if (isContiguous != NULL) {
            *isContiguous = TRUE;
        }
        physicalAddress = (UInt32)virtualAddress;
        goto Memory_getBufferPhysicalAddress_return;
    }

    if (sizeInBytes == 0) {
        GT_0trace(curTrace, GT_6CLASS, "Memory_getBufferPhysicalAddress> "
                "invalid buffer size provided (0)\n");

        /* Note that physicalAddress is already initialized to zero */
        goto Memory_getBufferPhysicalAddress_return;
    }

    /* first try to find the buffer in our tables */
    physicalAddress = getPhysicalAddress((UInt32)virtualAddress, sizeInBytes);

    if (physicalAddress != 0) {
        if (isContiguous != NULL) {
            *isContiguous = TRUE;
        }
    }
    else {
        /* ask CMEM to convert addresses of the first and the last byte */
        physicalAddress = CMEM_getPhys(virtualAddress);
        GT_2trace(curTrace, GT_1CLASS, "Memory_getBufferPhysicalAddress> "
                "CMEM_getPhys(0x%x) = 0x%x.\n", virtualAddress,
                physicalAddress);

        physicalAddressOfLastByte = CMEM_getPhys(
                (Ptr)((UInt32)virtualAddress + sizeInBytes - 1));

        if (physicalAddress != 0) {
            if (physicalAddressOfLastByte == physicalAddress + sizeInBytes - 1)
            {
                if (isContiguous != NULL) {
                    *isContiguous = TRUE;
                }
            }
            else {
                if (isContiguous != NULL) {
                    *isContiguous = FALSE;
                }
                else {
                    GT_2trace(curTrace, GT_7CLASS,
                            "Memory_getBufferPhysicalAddress> "
                            "ERROR: user buffer at addr=0x%x, size=%d is NOT "
                            "contiguous\n", virtualAddress, sizeInBytes);
                }

                /* invalid buffer - it's not contiguous. */
                physicalAddress = 0;
            }
        }
    }

Memory_getBufferPhysicalAddress_return:

    GT_1trace(curTrace, GT_ENTER, "Memory_getBufferPhysicalAddress> "
            "return (0x%x)\n", physicalAddress);

    Lock_release(moduleLock);

    return (physicalAddress);
}


/*
 *  ======== Memory_getBufferVirtualAddress ========
 *  Converts physical address to user virtual address.
 */
Ptr Memory_getBufferVirtualAddress(UInt32 physicalAddress, Int sizeInBytes)
{
    /*
     * Do the reverse mapping by looking at our list of buffers; if not found,
     * result will be 0.
     */

    UInt32 virtualAddress = 0;

    Lock_acquire( moduleLock );

    GT_2trace(curTrace, GT_ENTER, "Memory_getBufferVirtualAddress> "
            "Enter(physAddr=0x%x, size=%d)\n", physicalAddress, sizeInBytes);

    if (Memory_skipVirtualAddressTranslation == TRUE) {
        virtualAddress = physicalAddress;
        goto Memory_getBufferVirtualAddress_return;
    }

    if (sizeInBytes == 0) {
        GT_0trace(curTrace, GT_6CLASS, "Memory_getBufferVirtualAddress> "
                "invalid buffer size provided (0)\n");

        /* Note that virtualAddress is already initialized to zero */
        goto Memory_getBufferVirtualAddress_return;
    }

    virtualAddress = getVirtualAddress(physicalAddress, sizeInBytes);

Memory_getBufferVirtualAddress_return:

    GT_1trace(curTrace, GT_ENTER, "Memory_getBufferVirtualAddress> "
            "return (0x%x)\n", virtualAddress);

    Lock_release( moduleLock );

    return (Ptr)virtualAddress;
}


/*
 *  ======== Memory_cacheInv ========
 */
Void Memory_cacheInv(Ptr addr, Int sizeInBytes)
{
    CMEM_cacheInv(addr, sizeInBytes);
}


/*
 *  ======== Memory_cacheWb ========
 */
Void Memory_cacheWb(Ptr addr, Int sizeInBytes)
{
    CMEM_cacheWb(addr, sizeInBytes);
}


/*
 *  ======== Memory_cacheWbInv ========
 */
Void Memory_cacheWbInv(Ptr addr, Int sizeInBytes)
{
    CMEM_cacheWbInv(addr, sizeInBytes);
}

/*
 *  ======== Memory_cacheWbInvAll ========
 */
Void Memory_cacheWbInvAll()
{
}

/*
 *  ======== cleanup ========
 */
static Void cleanup(Void)
{
    ContigBuf *cb, *elem;

    if (curInit != FALSE) {
        curInit = FALSE;
        if (cmemInitialized) {
            CMEM_exit();
        }
        if (moduleLock != NULL) {
            Lock_delete(moduleLock);
        }
        /* free up contif buf list */
        cb = contigBufList;
        while (cb != NULL) {
            elem = cb;
            cb = cb->next;
            free(elem);
        }

        /* reinit static vars */
        contigBufList   = NULL;
        cmemInitialized = FALSE;
        moduleLock      = NULL;
    }
}

/*
 *  ======== Memory_registerContigBuf ========
 */
Void Memory_registerContigBuf(UInt32 virtualAddress, UInt32 sizeInBytes,
        UInt32 physicalAddress)
{
    addContigBuf(virtualAddress, sizeInBytes, physicalAddress);
}


/*
 *  ======== Memory_unregisterContigBuf ========
 */
Void Memory_unregisterContigBuf(UInt32 virtualAddress, UInt32 sizeInBytes)
{
    if (removeContigBuf(virtualAddress, sizeInBytes) < 0) {
        GT_2trace(curTrace, GT_6CLASS, "Memory_unregisterContigBuf> "
                  "Warning: buffer (addr=%d, size=%d) not found in "
                  "translation cache\n",
                  virtualAddress, sizeInBytes);
    }
}


/*
 *  ======== Memory_dumpKnownContigBufs ========
 */
Void Memory_dumpKnownContigBufsList()
{
    ContigBuf *cb;

    GT_0trace(curTrace, GT_5CLASS, "Memory_dumpKnownContigBufsList> "
            "following buffers were translated/registered:\n");

    cb = contigBufList;

    while (cb != NULL) {
        GT_3trace(curTrace, GT_5CLASS, "    [ virt: 0x%08lx, size: %08lu, "
                "phys: 0x%08lx ]\n", cb->virtualAddress, cb->sizeInBytes,
                cb->physicalAddress );
        cb = cb->next;
    }
}

/*
 *  @(#) ti.sdo.ce.osal.wince; 1, 0, 0,82; 12-2-2010 21:25:04; /db/atree/library/trees/ce/ce-r11x/src/ xlibrary

 */

